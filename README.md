# ğŸ¤– Q&A Chatbot with Ollama and LangChain

A simple yet powerful **Question & Answer Chatbot** built using **Streamlit**, **LangChain**, and **Ollama**.  
This app allows users to interact with local large language models (LLMs) like `gemma:2b` directly from a web interface.

---

## ğŸš€ Features

- ğŸ§  Built using **LangChain** for modular AI pipelines  
- ğŸ’¬ Uses **Ollama** for running local LLMs  
- ğŸŒ Interactive frontend with **Streamlit**  
- ğŸ”‘ Integrated with **LangSmith** for tracing and run tracking  
- âš™ï¸ Adjustable parameters (temperature, max tokens, model choice)

---

## ğŸ—ï¸ Project Structure

Q&A_ChatBot/
â”‚
â”œâ”€â”€ app_ollama.py # Main Streamlit application
â”œâ”€â”€ .env.example # Example environment file (no secrets)
â”œâ”€â”€ .gitignore # Git ignore rules
â”œâ”€â”€ requirements.txt # Dependencies
â””â”€â”€ README.md # Project documentation

yaml
Copy code

---

## ğŸ’» Installation

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/QnA_ChatBot.git
cd QnA_ChatBot
2ï¸âƒ£ Create a Virtual Environment
If you want to name it chatbot:

bash
Copy code
python -m venv chatbot
Activate it:

Windows:

bash
Copy code
chatbot\Scripts\activate
Mac/Linux:

bash
Copy code
source chatbot/bin/activate
3ï¸âƒ£ Install Dependencies
Install all required packages from requirements.txt:

bash
Copy code
pip install -r requirements.txt
4ï¸âƒ£ Configure Environment Variables
Create a .env file in the project root and add the following:

bash
Copy code
LANGCHAIN_API_KEY="your_langchain_api_key_here"
LANGCHAIN_PROJECT="Q&A_Chatbot"
LANGCHAIN_TRACING_V2=true
âš ï¸ Do not commit your .env file.
It is already ignored in .gitignore. You can use .env.example for reference.

5ï¸âƒ£ Run the App
Start the Streamlit app:

bash
Copy code
streamlit run app_ollama.py
Then open the URL shown in the terminal (usually http://localhost:8501).

ğŸ§© How It Works
Loads environment variables from .env using python-dotenv

Configures LangChain to use your LangSmith project for tracing

Lets users enter a question via Streamlit interface

Passes the query through a LangChain prompt â†’ Ollama LLM â†’ Output Parser

Displays the LLM-generated answer in the browser

âš™ï¸ Environment Variables Reference
Variable	Description
LANGCHAIN_API_KEY	Your LangSmith API key for tracking
LANGCHAIN_PROJECT	Project name visible in your LangSmith dashboard
LANGCHAIN_TRACING_V2	Enables LangSmith tracing (must be true)

ğŸ“Š LangSmith Integration
If everything is configured correctly, youâ€™ll see your chatbot runs appear under your LangSmith project dashboard:

ğŸ‘‰ https://smith.langchain.com

ğŸ§  Example Models (via Ollama)
You can modify or extend the dropdown list in the sidebar:

python
Copy code
llm_name = st.sidebar.selectbox("Select a model", ["gemma:2b", "llama3", "mistral", "phi3"])
To use these models, make sure theyâ€™re pulled locally via Ollama:

bash
Copy code
ollama pull gemma:2b
ğŸ§° Requirements
All required Python packages are listed in requirements.txt:

nginx
Copy code
streamlit
python-dotenv
langchain
langchain-community
langsmith
ollama
langchain-core
Install with:

bash
Copy code
pip install -r requirements.txt
ğŸ§¾ License
This project is open-source and available under the MIT License.

ğŸ§‘â€ğŸ’» Author
Laxman Sannu Gouda
ğŸ“§ [Add your email if you want]
ğŸ’¬ â€œBuilt with ğŸ’¡ LangChain, âš™ï¸ Streamlit, and ğŸ’­ Ollamaâ€
